# Agentic AI Testing System for Linux Kernel and BSP

An autonomous AI-powered testing platform that intelligently tests Linux kernels and Board Support Packages (BSPs) across diverse hardware configurations. The system leverages Large Language Models to generate test cases, analyze failures, and provide actionable feedback to developers.

**Project Goal:** Improve kernel and BSP quality through comprehensive, automated testing that adapts to code changes and discovers edge cases that traditional testing might miss.

---

## ğŸ“š Documentation

- **[Quick Start Guide](docs/QUICKSTART.md)** - Get up and running in minutes
- **[Architecture Overview](docs/ARCHITECTURE.md)** - System design and technical architecture
- **[Installation Guide](docs/INSTALLATION.md)** - Detailed installation instructions
- **[Contributing Guidelines](docs/CONTRIBUTING.md)** - How to contribute to the project
- **[Complete Overview](docs/CONFLUENCE_PAGE.md)** - Comprehensive project documentation
- **[Changelog](CHANGELOG.md)** - Project updates and version history

### Specifications
- [Requirements Document](.kiro/specs/agentic-kernel-testing/requirements.md) - Detailed system requirements
- [Design Document](.kiro/specs/agentic-kernel-testing/design.md) - Architecture and design decisions
- [Implementation Tasks](.kiro/specs/agentic-kernel-testing/tasks.md) - 50 tasks covering all system components

---

## ğŸš€ Recent Updates

**Latest:** December 3, 2025
- âœ… **Task List Refreshed:** Updated implementation plan with 50 comprehensive tasks
- âœ… **All Tests Required:** Comprehensive testing approach from the start (unit + property-based)
- âœ… **Infrastructure Complete:** Project structure and core infrastructure fully implemented
- âœ… **Documentation Updated:** All guides synchronized with latest project state
- âœ… **Testing Framework:** pytest and Hypothesis configured for unit and property-based testing
- âœ… **Configuration System:** Comprehensive settings system with pydantic-settings
- ğŸ“‹ **Ready for Task 2:** Core data models and interfaces implementation

---

## Core Capabilities

### ğŸ¤– Autonomous Test Generation
AI agents analyze code changes and automatically generate targeted test cases covering normal usage, boundary conditions, and error paths. Generates 10+ distinct test cases per modified function within 5 minutes.

### ğŸ–¥ï¸ Multi-Hardware Testing
Execute tests across virtual environments (QEMU, KVM) and physical hardware boards to ensure compatibility across x86_64, ARM, and RISC-V architectures.

### ğŸ’¥ Intelligent Fault Injection
Stress testing with memory failures, I/O errors, and timing variations to discover edge cases and race conditions. Detects crashes, hangs, memory leaks, and data corruption.

### ğŸ” Root Cause Analysis
AI-powered failure analysis that correlates issues with code changes, groups related failures, and provides suggested fixes with references to similar historical issues.

### ğŸ”’ Security Testing
Automated fuzzing and static analysis to detect vulnerabilities before production. Includes buffer overflows, use-after-free, and integer overflow detection.

### âš¡ Performance Monitoring
Continuous performance benchmarking with regression detection and profiling. Tracks throughput, latency, and resource utilization with commit-level attribution.

### ğŸ”„ CI/CD Integration
Seamless integration with GitHub, GitLab, and Jenkins. Automatic test triggering on commits, PRs, and branch updates with real-time status reporting.

---

## Target Users

| User Role | Use Case |
|-----------|----------|
| **Kernel Developers** | Validate code changes without manually writing extensive tests |
| **BSP Maintainers** | Ensure hardware compatibility across different boards and architectures |
| **QA Engineers** | Discover edge cases through intelligent fault injection |
| **Security Researchers** | Identify vulnerabilities before production |
| **Performance Engineers** | Track and prevent performance regressions |
| **CI/CD Administrators** | Automate testing workflows in development pipelines |

## Technology Stack

| Category | Technologies |
|----------|-------------|
| **Language** | Python 3.10+ |
| **AI/ML** | Amazon Q APIs (built on Amazon Bedrock for LLM access), Hypothesis (property-based testing) |
| **Testing** | pytest, gcov/lcov, Syzkaller (fuzzing), Coccinelle (static analysis), KASAN, KTSAN |
| **Virtualization** | QEMU, KVM, SSH for physical hardware |
| **Performance** | LMBench, FIO, Netperf, perf |
| **Data** | PostgreSQL/SQLite, FastAPI/Flask |
| **Frontend** | React/Vue for web dashboard |
| **Deployment** | Docker, Kubernetes |

## Project Structure

```
â”œâ”€â”€ ai_generator/       # AI-powered test generation (âœ… Structure created)
â”œâ”€â”€ orchestrator/       # Test scheduling and resource management (âœ… Structure created)
â”œâ”€â”€ execution/          # Test runners and environment managers (âœ… Structure created)
â”œâ”€â”€ analysis/           # Coverage, performance, security analysis (âœ… Structure created)
â”œâ”€â”€ integration/        # CI/CD hooks and VCS integration (âœ… Structure created)
â”œâ”€â”€ api/               # REST API server
â”œâ”€â”€ dashboard/         # Web UI for monitoring
â”œâ”€â”€ cli/               # Command-line interface
â”œâ”€â”€ config/            # Configuration management (âœ… Settings system implemented)
â”œâ”€â”€ tests/             # Unit, property-based, and integration tests (âœ… Framework configured)
â”œâ”€â”€ docs/              # Comprehensive documentation (âœ… Created)
â””â”€â”€ .kiro/
    â”œâ”€â”€ specs/         # Feature specifications (âœ… Complete)
    â””â”€â”€ steering/      # AI assistant guidance (âœ… Complete)
```

## Getting Started

### Prerequisites

- Python 3.10 or higher
- Poetry or pip for dependency management
- Docker (optional, for containerized deployment)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd agentic-kernel-testing
   ```

2. **Install dependencies**
   ```bash
   # Using Poetry (recommended)
   poetry install
   
   # Or using pip
   pip install -r requirements.txt
   
   # Or install in development mode
   pip install -e ".[dev]"
   ```

3. **Configure environment**
   ```bash
   # Copy example configuration
   cp .env.example .env
   
   # Edit .env with your settings (API keys, database config, etc.)
   nano .env
   ```

4. **Verify setup**
   ```bash
   # Run verification script
   python3 verify_setup.py
   ```

### Running Tests

```bash
# Run all tests
pytest

# Run unit tests
pytest tests/unit/

# Run property-based tests (100+ iterations)
pytest tests/property/ --hypothesis-iterations=100

# Run with coverage
pytest --cov=. --cov-report=html
```

## Development

### Code Quality

```bash
# Type checking
mypy .

# Linting
pylint ai_generator orchestrator execution analysis integration

# Format code
black .
isort .
```

### Running the System

```bash
# Start API server
python -m api.server

# Start web dashboard
cd dashboard && npm run dev

# CLI tool
python -m cli.main --help
```

## Key Features

âœ… Generates test cases within 5 minutes of code commit  
âœ… Tests across multiple hardware configurations automatically  
âœ… Detects crashes, hangs, memory leaks, and data corruption  
âœ… Tracks code coverage (line, branch, function) with gap identification  
âœ… Performs security fuzzing and vulnerability detection  
âœ… Monitors performance with baseline comparison and trend analysis  
âœ… Validates kernel configuration options (minimal, default, maximal)  
âœ… Efficient resource management with automatic cleanup and scaling  

---

## Project Status

**Current Phase:** Active Development ğŸš€

The system architecture has been fully defined with comprehensive requirements covering:
- âœ… AI-driven test generation and analysis
- âœ… Multi-environment test execution
- âœ… Coverage tracking and gap identification
- âœ… Security scanning and fuzzing
- âœ… Performance monitoring and regression detection
- âœ… CI/CD integration

**Implementation Progress:**
- âœ… **Task 1 Complete (Dec 3, 2025):** Project structure and core infrastructure
  - Directory structure created for all components (ai_generator, orchestrator, execution, analysis, integration)
  - Python project configured with Poetry and pip
  - Testing framework (pytest) and Hypothesis configured with 100+ iterations
  - Comprehensive configuration system implemented with pydantic-settings
  - Settings classes for LLM, database, execution, coverage, security, performance, and notifications
  - Test fixtures and conftest.py for shared test utilities
  - Verification script (verify_setup.py) confirms all structure is correct
- ğŸ“‹ **Task 2 Ready:** Core data models and interfaces
  - Next: Implementing TestCase, TestResult, CodeAnalysis, FailureAnalysis, HardwareConfig, Environment
  - Includes serialization/deserialization and validation logic

**Development Methodology:** Following spec-driven development with comprehensive testing (unit + property-based) to ensure correctness across all 50 implementation tasks.

## Contributing

We welcome contributions! Please see our [Contributing Guidelines](docs/CONTRIBUTING.md) for details on how to get started.

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## Contact & Collaboration

For questions or collaboration opportunities, please reach out through GitHub issues or contact the project maintainers.

**Project Maintainer:** Charles Liu

---

**Last Updated:** December 3, 2025
